{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9fd263f-0f92-490b-b8ce-5a67f3f6e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        scaler,\n",
    "        channel,\n",
    "        num_nodes,\n",
    "        seq_len,\n",
    "        pred_len,\n",
    "        dropout_n,\n",
    "        d_llm,\n",
    "        e_layer,\n",
    "        head,\n",
    "        lrate,\n",
    "        wdecay,\n",
    "        feature_w,\n",
    "        fcst_w,\n",
    "        recon_w,\n",
    "        att_w,\n",
    "        device,\n",
    "        epochs\n",
    "    ):\n",
    "        self.model = Dual(\n",
    "            device=device, channel=channel, num_nodes=num_nodes, seq_len=seq_len, pred_len=pred_len, \n",
    "            dropout_n=dropout_n, d_llm=d_llm, e_layer=e_layer, head=head\n",
    "        )\n",
    "        \n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=lrate, weight_decay=wdecay)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=min(epochs, 100), eta_min=1e-8, verbose=True)\n",
    "        self.MSE = MSE\n",
    "        self.MAE = MAE\n",
    "        self.clip = 5\n",
    "        self.scaler = scaler\n",
    "        self.device = device\n",
    "\n",
    "        self.feature_loss = 'smooth_l1'  \n",
    "        self.fcst_loss = 'smooth_l1'\n",
    "        self.recon_loss = 'smooth_l1'\n",
    "        self.att_loss = 'smooth_l1'   \n",
    "        self.fcst_w = 1\n",
    "        self.recon_w = 0.5\n",
    "        self.feature_w = 0.1     \n",
    "        self.att_w = 0.01\n",
    "        self.criterion = KDLoss(self.feature_loss, self.fcst_loss, self.recon_loss, self.att_loss,  self.feature_w,  self.fcst_w,  self.recon_w,  self.att_w)\n",
    "\n",
    "        # print(\"The number of trainable parameters: {}\".format(self.model.count_trainable_params()))\n",
    "        print(\"The number of parameters: {}\".format(self.model.param_num()))\n",
    "        print(self.model)\n",
    "\n",
    "    def train(self, x, y, emb):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att = self.model(x, emb)\n",
    "        loss = self.criterion(ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att, y)\n",
    "        loss.backward()\n",
    "        if self.clip is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip) \n",
    "        self.optimizer.step() \n",
    "        mse = self.MSE(ts_out, y) \n",
    "        mae = self.MAE(ts_out, y)\n",
    "        return loss.item(), mse.item(), mae.item()\n",
    "\n",
    "    def eval(self, x, y, emb):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att = self.model(x, emb)\n",
    "            loss = self.criterion(ts_enc, prompt_enc, ts_out, prompt_out, ts_att, prompt_att, y)\n",
    "            mse = self.MSE(ts_out, y)\n",
    "            mae = self.MAE(ts_out, y)\n",
    "        return loss.item(), mse.item(), mae.item()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde90d8b-ed0a-4f6e-a504-5b279baa3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda:6\", help=\"\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"ETTh1\", help=\"data path\")\n",
    "    parser.add_argument(\"--channel\", type=int, default=512, help=\"number of features\")\n",
    "    parser.add_argument(\"--num_nodes\", type=int, default=7, help=\"number of nodes\")\n",
    "    parser.add_argument(\"--seq_len\", type=int, default=96, help=\"seq_len\")\n",
    "    parser.add_argument(\"--pred_len\", type=int, default=96, help=\"out_len\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32, help=\"batch size\")\n",
    "    parser.add_argument(\"--lrate\", type=float, default=1e-4, help=\"learning rate\")\n",
    "    parser.add_argument(\"--dropout_n\", type=float, default=0.2, help=\"dropout rate of neural network layers\")\n",
    "    parser.add_argument(\"--d_llm\", type=int, default=768, help=\"hidden dimensions\")\n",
    "    parser.add_argument(\"--e_layer\", type=int, default=1, help=\"layers of transformer encoder\")\n",
    "    parser.add_argument(\"--head\", type=int, default=8, help=\"heads of attention\")\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"gpt2\", help=\"llm\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=1e-3, help=\"weight decay rate\")\n",
    "    parser.add_argument(\"--feature_w\", type=float, default=0.01, help=\"weight of feature kd loss\")\n",
    "    parser.add_argument(\"--fcst_w\", type=float, default=1, help=\"weight of forecast loss\")\n",
    "    parser.add_argument(\"--recon_w\", type=float, default=0.5, help=\"weight of reconstruction loss\")\n",
    "    parser.add_argument(\"--att_w\", type=float, default=0.01, help=\"weight of attention kd loss\")\n",
    "    parser.add_argument('--num_workers', type=int, default=10, help='data loader num workers')\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100, help=\"\")\n",
    "    parser.add_argument('--seed', type=int, default=2036, help='random seed')\n",
    "    parser.add_argument(\n",
    "        \"--es_patience\",\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help=\"quit if no improvement after this many iterations\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--save\",\n",
    "        type=str,\n",
    "        default=\"./logs/\" + str(time.strftime(\"%Y-%m-%d-%H:%M:%S\")) + \"-\",\n",
    "        help=\"save path\",\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf89f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    data_map = {\n",
    "        'ETTh1': Dataset_ETT_hour,\n",
    "        'ETTh2': Dataset_ETT_hour,\n",
    "        'ETTm1': Dataset_ETT_minute,\n",
    "        'ETTm2': Dataset_ETT_minute\n",
    "        }\n",
    "    data_class = data_map.get(args.data_path, Dataset_Custom)\n",
    "    train_set = data_class(flag='train', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    val_set = data_class(flag='val', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    test_set = data_class(flag='test', scale=True, size=[args.seq_len, 0, args.pred_len], data_path=args.data_path)\n",
    "    \n",
    "    scaler = train_set.scaler\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=False, drop_last=True, num_workers=args.num_workers)\n",
    "    val_loader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=True, num_workers=args.num_workers)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, drop_last=False, num_workers=args.num_workers)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1260332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48450fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = torch.tensor([[[[0,0,0],[0,0,0]]]]).permute(3,2,1,0)\n",
    "aaa\n",
    "aaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df095b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9157a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_provider.data_loader_emb import Dataset_ETT_hour #, Dataset_ETT_minute, Dataset_Custom\n",
    "# from model.TimeKD import Dual\n",
    "# from utils.kd_loss import KDLoss\n",
    "# from utils.metrics import MSE, MAE, metric\n",
    "# import faulthandler\n",
    "# faulthandler.enable()\n",
    "# torch.cuda.empty_cache()\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:150\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e058a880-7811-461c-8ba2-20c6e18f455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "# args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d4174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5576b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.90M/2.90M [00:02<00:00, 1.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to American Express - Default Prediction"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "model_specs_template =  \"{args.data_type}_{args.sampling}_{args.lrate}_{args.seed}_{args.pred_len}_{args.channel}_{args.e_layer}_{args.dropout_n}_{args.att_w}\"\n",
    "model_specs = \"original_10pct_0.0001_42_1_512_1_0.2_0.01\"\n",
    "model_path = f\"./logs/Amex/{model_specs}/\"\n",
    "os.system(f\"kaggle competitions submit -c amex-default-prediction -f {model_path}/submission.csv.zip -m '{model_specs_template}: {model_specs}' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99d98f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eb30a0478065f59c99dd4a75645fd2aef9ae42f05bf959...</td>\n",
       "      <td>0.127577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb30a0478065f59c99dd4a75645fd2aef9ae42f05bf959...</td>\n",
       "      <td>0.002824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  prediction\n",
       "0  eb30a0478065f59c99dd4a75645fd2aef9ae42f05bf959...    0.127577\n",
       "1  eb30a0478065f59c99dd4a75645fd2aef9ae42f05bf959...    0.002824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"{model_path}/submission.csv.zip\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94c392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6284dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: /export/home2/zongqi001/000_data/amex/13month_0.1pct\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_path = '/export/home2/zongqi001/000_data/amex/13month_0.1pct'\n",
    "print(f'input_path: {input_path}')\n",
    "\n",
    "test_series     = pd.read_feather(f'{input_path}/df_nn_series_test.feather')\n",
    "test_series_idx = pd.read_feather(f'{input_path}/df_nn_series_idx_test.feather').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba29161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer_ID\n",
      "S_2\n",
      "P_2\n",
      "D_39\n",
      "B_1\n",
      "B_2\n",
      "R_1\n",
      "S_3\n",
      "D_41\n",
      "B_3\n",
      "D_42\n",
      "D_43\n",
      "D_44\n",
      "B_4\n",
      "D_45\n",
      "B_5\n",
      "R_2\n",
      "D_46\n",
      "D_47\n",
      "D_48\n",
      "D_49\n",
      "B_6\n",
      "B_7\n",
      "B_8\n",
      "D_50\n",
      "D_51\n",
      "B_9\n",
      "R_3\n",
      "D_52\n",
      "P_3\n",
      "B_10\n",
      "D_53\n",
      "S_5\n",
      "B_11\n",
      "S_6\n",
      "D_54\n",
      "R_4\n",
      "S_7\n",
      "B_12\n",
      "S_8\n",
      "D_55\n",
      "D_56\n",
      "B_13\n",
      "R_5\n",
      "D_58\n",
      "S_9\n",
      "B_14\n",
      "D_59\n",
      "D_60\n",
      "D_61\n",
      "B_15\n",
      "S_11\n",
      "D_62\n",
      "D_65\n",
      "B_16\n",
      "B_17\n",
      "B_18\n",
      "B_19\n",
      "B_20\n",
      "S_12\n",
      "R_6\n",
      "S_13\n",
      "B_21\n",
      "D_69\n",
      "B_22\n",
      "D_70\n",
      "D_71\n",
      "D_72\n",
      "S_15\n",
      "B_23\n",
      "D_73\n",
      "P_4\n",
      "D_74\n",
      "D_75\n",
      "D_76\n",
      "B_24\n",
      "R_7\n",
      "D_77\n",
      "B_25\n",
      "B_26\n",
      "D_78\n",
      "D_79\n",
      "R_8\n",
      "R_9\n",
      "S_16\n",
      "D_80\n",
      "R_10\n",
      "R_11\n",
      "B_27\n",
      "D_81\n",
      "D_82\n",
      "S_17\n",
      "R_12\n",
      "B_28\n",
      "R_13\n",
      "D_83\n",
      "R_14\n",
      "R_15\n",
      "D_84\n",
      "R_16\n",
      "B_29\n",
      "S_18\n",
      "D_86\n",
      "D_87\n",
      "R_17\n",
      "R_18\n",
      "D_88\n",
      "B_31\n",
      "S_19\n",
      "R_19\n",
      "B_32\n",
      "S_20\n",
      "R_20\n",
      "R_21\n",
      "B_33\n",
      "D_89\n",
      "R_22\n",
      "R_23\n",
      "D_91\n",
      "D_92\n",
      "D_93\n",
      "D_94\n",
      "R_24\n",
      "R_25\n",
      "D_96\n",
      "S_22\n",
      "S_23\n",
      "S_24\n",
      "S_25\n",
      "S_26\n",
      "D_102\n",
      "D_103\n",
      "D_104\n",
      "D_105\n",
      "D_106\n",
      "D_107\n",
      "B_36\n",
      "B_37\n",
      "R_26\n",
      "R_27\n",
      "D_108\n",
      "D_109\n",
      "D_110\n",
      "D_111\n",
      "B_39\n",
      "D_112\n",
      "B_40\n",
      "S_27\n",
      "D_113\n",
      "D_115\n",
      "D_118\n",
      "D_119\n",
      "D_121\n",
      "D_122\n",
      "D_123\n",
      "D_124\n",
      "D_125\n",
      "D_127\n",
      "D_128\n",
      "D_129\n",
      "B_41\n",
      "B_42\n",
      "D_130\n",
      "D_131\n",
      "D_132\n",
      "D_133\n",
      "R_28\n",
      "D_134\n",
      "D_135\n",
      "D_136\n",
      "D_137\n",
      "D_138\n",
      "D_139\n",
      "D_140\n",
      "D_141\n",
      "D_142\n",
      "D_143\n",
      "D_144\n",
      "D_145\n",
      "oneHot_B_30_0.0\n",
      "oneHot_B_30_100.0\n",
      "oneHot_B_30_200.0\n",
      "oneHot_B_38_100.0\n",
      "oneHot_B_38_200.0\n",
      "oneHot_B_38_300.0\n",
      "oneHot_B_38_400.0\n",
      "oneHot_B_38_500.0\n",
      "oneHot_B_38_600.0\n",
      "oneHot_B_38_700.0\n",
      "oneHot_D_114_0.0\n",
      "oneHot_D_114_100.0\n",
      "oneHot_D_116_0.0\n",
      "oneHot_D_117_-100.0\n",
      "oneHot_D_117_100.0\n",
      "oneHot_D_117_200.0\n",
      "oneHot_D_117_300.0\n",
      "oneHot_D_117_400.0\n",
      "oneHot_D_117_500.0\n",
      "oneHot_D_117_600.0\n",
      "oneHot_D_120_0.0\n",
      "oneHot_D_120_100.0\n",
      "oneHot_D_126_-100.0\n",
      "oneHot_D_126_0.0\n",
      "oneHot_D_126_100.0\n",
      "oneHot_D_63_0\n",
      "oneHot_D_63_3\n",
      "oneHot_D_63_4\n",
      "oneHot_D_63_5\n",
      "oneHot_D_64_-1\n",
      "oneHot_D_64_0\n",
      "oneHot_D_64_1\n",
      "oneHot_D_64_2\n",
      "oneHot_D_64_3\n",
      "oneHot_D_66_0.0\n",
      "oneHot_D_66_100.0\n",
      "oneHot_D_68_0.0\n",
      "oneHot_D_68_100.0\n",
      "oneHot_D_68_200.0\n",
      "oneHot_D_68_300.0\n",
      "oneHot_D_68_400.0\n",
      "oneHot_D_68_500.0\n",
      "oneHot_D_68_600.0\n"
     ]
    }
   ],
   "source": [
    "for i in test_series.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed0d163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c667879ff93be3618d20d790f7d449739dc87aa9e0d6ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c689a7ed32975f7587b190f76df24831624f7c60a4e9e5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_ID\n",
       "0   c667879ff93be3618d20d790f7d449739dc87aa9e0d6ea...\n",
       "13  c689a7ed32975f7587b190f76df24831624f7c60a4e9e5..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = test_series[['customer_ID']].iloc[test_series_idx[:, 0]].copy()\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb035512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439bd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d7279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: /export/home2/zongqi001/000_data/amex/13month_0.1pct\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "input_path = '/export/home2/zongqi001/000_data/amex/13month_0.1pct'\n",
    "print(f'input_path: {input_path}')\n",
    "\n",
    "trainval_series     = pd.read_feather(f'{input_path}/df_nn_series_train.feather')\n",
    "trainval_series_idx = pd.read_feather(f'{input_path}/df_nn_series_idx_train.feather').values\n",
    "trainval_y = pd.read_csv(f'{input_path}/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c85ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99cf160",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_index, (trn_index, val_index) in enumerate(skf.split(trainval_y,trainval_y['target'])):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38e096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.TimeKD import Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24bc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Dual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc905a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dcbed01",
   "metadata": {},
   "source": [
    "### test h5 for 3D matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fb3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939aaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Amex_Dataset:\n",
    "    # def __init__(self,df_series,df_feature,uidxs,df_y=None):\n",
    "    def __init__(self,df_series,uidxs,df_y=None,label_name = 'target',id_name = 'customer_ID'):\n",
    "        self.df_series = df_series\n",
    "        # self.df_feature = df_feature\n",
    "        self.df_y = df_y\n",
    "        self.uidxs = uidxs\n",
    "        self.label_name = label_name\n",
    "        self.id_name = id_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.uidxs))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        i1,i2,idx = self.uidxs[index]\n",
    "        series = self.df_series.iloc[i1:i2+1,1:].drop(['S_2'],axis=1).values\n",
    "        time_ref = self.df_series.iloc[i1:i2+1,1:]['S_2']\n",
    "        # series = self.df_series.iloc[i1:i2+1,1:].drop(['year_month','S_2'],axis=1).values\n",
    "\n",
    "        if len(series.shape) == 1:\n",
    "            series = series.reshape((-1,)+series.shape[-1:])\n",
    "        # series_ = series.copy()\n",
    "        # series_[series_!=0] = 1.0 - series_[series_!=0] + 0.001\n",
    "        # feature = self.df_feature.loc[idx].values[1:]\n",
    "        # feature_ = feature.copy()\n",
    "        # feature_[feature_!=0] = 1.0 - feature_[feature_!=0] + 0.001\n",
    "        \n",
    "        emb_path = f\"/export/home2/zongqi001/004_TimeKD/TimeKD/amex_emb/train/\"\n",
    "        file_path = os.path.join(emb_path, f\"{idx}.h5\")\n",
    "\n",
    "        with h5py.File(file_path, 'r') as hf:\n",
    "            emb_data = hf['stacked_embeddings'][:]\n",
    "            emb_tensor = torch.from_numpy(emb_data)\n",
    "\n",
    "        if self.df_y is not None:\n",
    "            label = self.df_y.loc[idx,[self.label_name]].values\n",
    "            return {\n",
    "                    'SERIES': series,#np.concatenate([series,series_],axis=1),\n",
    "                    # 'FEATURE': np.concatenate([feature,feature_]),\n",
    "                    'LABEL': label,\n",
    "                    'time_ref': time_ref,\n",
    "                    'idx': idx,\n",
    "                    'emb_tensor': emb_tensor,\n",
    "                    }\n",
    "        else:\n",
    "            return {\n",
    "                    'SERIES': series,#np.concatenate([series,series_],axis=1),\n",
    "                    # 'FEATURE': np.concatenate([feature,feature_]),\n",
    "                    'time_ref': time_ref,\n",
    "                    'idx': idx,\n",
    "                    }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        Padding to same size.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = len(batch)\n",
    "        batch_series = torch.zeros((batch_size, 13, batch[0]['SERIES'].shape[1]))\n",
    "        batch_mask = torch.zeros((batch_size, 13))\n",
    "        # batch_feature = torch.zeros((batch_size, batch[0]['FEATURE'].shape[0]))\n",
    "        batch_y = torch.zeros(batch_size)\n",
    "        batch_time_ref = np.array([sample['time_ref'] for sample in batch])\n",
    "        batch_idx = np.array([sample['idx'] for sample in batch])\n",
    "        batch_emb_tensor = None\n",
    "\n",
    "        for i, item in enumerate(batch):\n",
    "            v = item['SERIES']\n",
    "            batch_series[i, :v.shape[0], :] = torch.tensor(v).float()\n",
    "            batch_mask[i,:v.shape[0]] = 1.0\n",
    "            # v = item['FEATURE'].astype(np.float32)\n",
    "            # batch_feature[i] = torch.tensor(v).float()\n",
    "            if self.df_y is not None:\n",
    "                v = item['LABEL'].astype(np.float32)\n",
    "                batch_y[i] = torch.tensor(v).float()\n",
    "                batch_emb_tensor = torch.stack([sample['emb_tensor'] for sample in batch], dim=0) \n",
    "\n",
    "        return {'batch_series':batch_series\n",
    "                ,'batch_mask':batch_mask\n",
    "                # ,'batch_feature':batch_feature\n",
    "                ,'batch_y':batch_y\n",
    "                ,'batch_time_ref':batch_time_ref\n",
    "                ,'batch_idx':batch_idx\n",
    "                ,'batch_emb_tensor':batch_emb_tensor\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7a8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/export/home2/zongqi001/000_data/amex/13month_0.1pct'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee341c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series     = pd.read_feather(f'{input_path}/df_nn_series_train.feather')\n",
    "train_series_idx = pd.read_feather(f'{input_path}/df_nn_series_idx_train.feather').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a66fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(f'{input_path}/train_labels.csv')\n",
    "train_dataset = Amex_Dataset(train_series,train_series_idx,train_y)\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=4,shuffle=True, drop_last=False, collate_fn=train_dataset.collate_fn,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d93fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be21543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000f8675ede66cc6affd4c048db11a00246d7ee623f453...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00def60d36bbb3f6a51dcf0e8a999ab2c383813ec7e8ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  target\n",
       "0  000f8675ede66cc6affd4c048db11a00246d7ee623f453...       0\n",
       "1  00def60d36bbb3f6a51dcf0e8a999ab2c383813ec7e8ca...       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a084aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26, 38,  2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_series_idx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333043e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1pct\n"
     ]
    }
   ],
   "source": [
    "sampling = None\n",
    "sampling = '1pct'\n",
    "\n",
    "s = f'data_{sampling}' if sampling else f'data'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93d3d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "skf = StratifiedKFold(n_splits = 2, shuffle=True, random_state=42)\n",
    "fold1, fold2 = skf.split(train_y,train_y['target'])\n",
    "trn_index, val_index = fold1[0], fold1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059cc60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   3,   5,   6,   7,   9,  12,  13,  15,  17,  19,  22,  23,\n",
       "        29,  34,  39,  40,  41,  42,  45,  46,  48,  49,  50,  51,  52,\n",
       "        53,  55,  58,  60,  61,  62,  65,  66,  68,  69,  70,  72,  74,\n",
       "        77,  81,  86,  90,  92,  96,  97,  99, 100, 102, 105, 107, 110,\n",
       "       114, 117, 120, 121, 122, 123, 124, 126, 130, 131, 133, 136, 137,\n",
       "       138, 139, 142, 144, 152, 156, 157, 158, 160, 161, 162, 163, 165,\n",
       "       166, 169, 170, 172, 174, 175, 176, 178, 179, 183, 185, 186, 189,\n",
       "       192, 193, 194, 196, 199, 200, 201, 202, 203, 204, 205, 207, 208,\n",
       "       209, 210, 214, 216, 217])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c220956b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   4,   8,  10,  11,  14,  16,  18,  20,  21,  24,  25,\n",
       "        26,  27,  28,  30,  31,  32,  33,  35,  36,  37,  38,  43,  44,\n",
       "        47,  54,  56,  57,  59,  63,  64,  67,  71,  73,  75,  76,  78,\n",
       "        79,  80,  82,  83,  84,  85,  87,  88,  89,  91,  93,  94,  95,\n",
       "        98, 101, 103, 104, 106, 108, 109, 111, 112, 113, 115, 116, 118,\n",
       "       119, 125, 127, 128, 129, 132, 134, 135, 140, 141, 143, 145, 146,\n",
       "       147, 148, 149, 150, 151, 153, 154, 155, 159, 164, 167, 168, 171,\n",
       "       173, 177, 180, 181, 182, 184, 187, 188, 190, 191, 195, 197, 198,\n",
       "       206, 211, 212, 213, 215])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20faa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# for iter, data in enumerate(tqdm(train_dataloader)):\n",
    "#     print(iter, len(data['batch_series']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_series     = pd.read_feather(f'{input_path}/df_nn_series_test.feather')\n",
    "test_series_idx = pd.read_feather(f'{input_path}/df_nn_series_idx_test.feather').values\n",
    "test_y = pd.read_csv(f'{input_path}/test_labels.csv')['target']\n",
    "\n",
    "test_dataset = Amex_Dataset(test_series,test_series_idx)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=4,shuffle=True, drop_last=False, collate_fn=test_dataset.collate_fn,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2103c219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ca1af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 25,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_series_idx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cfd6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 21.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "1 4\n",
      "2 4\n",
      "3 4\n",
      "4 4\n",
      "5 4\n",
      "6 4\n",
      "7 4\n",
      "8 4\n",
      "9 4\n",
      "10 4\n",
      "11 4\n",
      "12 4\n",
      "13 4\n",
      "14 4\n",
      "15 4\n",
      "16 4\n",
      "17 4\n",
      "18 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for iter1, data in enumerate(tqdm(test_dataloader)):\n",
    "    print(iter1, len(data['batch_series']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c940bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0edfcc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home2/zongqi001/001_env/001_miniconda/001_mininconda/envs/amex__TimeKD/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from utils.tools import StandardScaler\n",
    "from model.TimeKD import Dual\n",
    "from utils.kd_loss import KDLoss\n",
    "from utils.metrics import MSE, MAE, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "252d4fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home2/zongqi001/001_env/001_miniconda/001_mininconda/envs/amex__TimeKD/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "The number of parameters: 8809260\n",
      "Dual(\n",
      "  (normalize_layers): Normalize()\n",
      "  (length_to_feature): Linear(in_features=13, out_features=512, bias=True)\n",
      "  (token_to_feature): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (ts_encoder): Encoder(\n",
      "    (attn_layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(512, 3072, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(3072, 512, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (prompt_encoder): Encoder(\n",
      "    (attn_layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(512, 3072, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(3072, 512, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (ts_proj): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (ts_proj2): Sequential(\n",
      "    (0): LayerNorm((220,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=220, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      "  (prompt_proj): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (prompt_proj2): Sequential(\n",
      "    (0): LayerNorm((220,), eps=1e-05, elementwise_affine=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=220, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "engine = trainer(\n",
    "    scaler=StandardScaler,\n",
    "    channel=512,\n",
    "    num_nodes=220,\n",
    "    seq_len=13,\n",
    "    pred_len=1,\n",
    "    dropout_n=0.2,\n",
    "    d_llm=768,\n",
    "    e_layer=1,\n",
    "    head=8,\n",
    "    lrate=1e-4,\n",
    "    wdecay=1e-3,\n",
    "    feature_w=0.01,\n",
    "    fcst_w=1,\n",
    "    recon_w=0.5,\n",
    "    att_w=0.01,\n",
    "    device=\"cpu\",\n",
    "    epochs=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:01<00:00, 47.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# for iter1, data_last in enumerate(tqdm(train_dataloader)):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d04213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 22.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for iter1, data_last in enumerate(tqdm(test_dataloader)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f1e38ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 220])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['batch_series'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78f6c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['batch_y']\n",
    "x = data['batch_series']\n",
    "emb_tensor = data['batch_emb_tensor']\n",
    "device = 'cpu'\n",
    "trainx = torch.Tensor(x).to(device).float()\n",
    "trainy = torch.Tensor(y).to(device).float()\n",
    "emb = torch.Tensor(emb_tensor).to(device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee91ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = engine.train(trainx, trainy, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77d765d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12315793335437775, 0.2463158667087555, 0.47641435265541077)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55e2756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 13, 220])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = next(iter(test_dataloader))\n",
    "aaa['batch_series'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05679e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_series\n",
      "batch_mask\n",
      "batch_y\n",
      "batch_time_ref\n",
      "batch_idx\n",
      "batch_emb_tensor\n"
     ]
    }
   ],
   "source": [
    "for item in aaa:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c23b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fe9e0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/export/home2/zongqi001/004_TimeKD/TimeKD/logs/Amex/1_512_1_0.0001_0.2_42_0.01/best_model.pth'\n",
    "engine.model.load_state_dict(torch.load(path, map_location=torch.device('cpu')), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95e5922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testx shape: torch.Size([4, 13, 220])\n",
      "preds len: torch.Size([4])\n",
      "preds: (tensor([[[ 0.6451, -0.0119, -0.9287,  ..., -0.2492,  0.7468, -0.9597],\n",
      "         [ 0.6600,  0.2520, -0.7379,  ...,  0.0831,  0.3457, -0.6377],\n",
      "         [ 1.6661, -0.3234, -0.7198,  ...,  1.0208,  0.3167,  0.0920],\n",
      "         ...,\n",
      "         [ 1.6447,  0.2347, -0.8127,  ...,  0.1912,  0.0680, -0.5167],\n",
      "         [ 1.4680,  0.5246, -0.4868,  ...,  0.2213,  0.1872,  0.2498],\n",
      "         [ 1.4589, -0.3334,  0.4941,  ...,  0.5517,  0.3376, -0.2136]],\n",
      "\n",
      "        [[ 0.4480,  0.4861, -0.2290,  ..., -1.9047,  0.5211,  0.2954],\n",
      "         [ 0.6513, -0.6885,  0.6580,  ...,  0.0853, -0.3880,  0.2479],\n",
      "         [ 2.8270,  0.2287, -1.4148,  ...,  0.9289, -0.4948, -0.1103],\n",
      "         ...,\n",
      "         [ 0.8056,  0.3727, -0.4812,  ...,  0.4020,  0.3636,  0.3260],\n",
      "         [ 1.7412,  0.3133,  0.4320,  ...,  0.5747,  0.4761, -0.4457],\n",
      "         [ 1.8720, -0.1302, -0.9207,  ...,  0.2930,  0.5951, -0.2599]],\n",
      "\n",
      "        [[ 0.5499, -0.1574, -0.6122,  ..., -0.5587, -0.6681, -0.5462],\n",
      "         [ 1.7949,  0.3465, -0.9267,  ...,  0.6950,  0.1953,  0.1621],\n",
      "         [ 1.0695,  0.3392, -0.9689,  ...,  0.4890,  0.0986,  0.3104],\n",
      "         ...,\n",
      "         [ 2.0784,  0.2297,  0.3313,  ...,  0.6031,  0.1512,  0.2238],\n",
      "         [ 2.1998, -0.1491, -0.9754,  ..., -0.2801,  0.2932, -0.3315],\n",
      "         [ 1.2174, -0.5758, -0.6649,  ..., -0.6614, -0.2495,  0.0151]],\n",
      "\n",
      "        [[ 1.2581, -0.2194, -1.7039,  ..., -0.6879,  0.8650, -1.1739],\n",
      "         [ 1.9545,  0.5653, -0.5967,  ..., -1.1675, -0.1124, -0.6967],\n",
      "         [ 2.0902, -0.6427, -0.7203,  ..., -0.7143, -0.3084, -0.6225],\n",
      "         ...,\n",
      "         [ 0.0943, -1.1799, -0.6471,  ..., -0.5350, -0.1717,  0.0080],\n",
      "         [ 1.4614, -0.5203,  0.4375,  ...,  0.1874,  0.5716, -0.6930],\n",
      "         [ 1.9067,  0.0127, -0.8525,  ...,  0.2155,  0.5493, -0.3107]]]), None, tensor([0.0040, 0.0101, 0.0189, 0.0311]), None, None, None)\n"
     ]
    }
   ],
   "source": [
    "data = aaa\n",
    "\n",
    "x = data['batch_series']\n",
    "\n",
    "testx = torch.Tensor(x).to(device).float()\n",
    "\n",
    "print('testx shape:', testx.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = engine.model(testx, None)\n",
    "print('preds len:', preds[2].shape)\n",
    "print('preds:', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2968c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42444230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96582dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testx shape: torch.Size([1, 13, 220])\n",
      "preds len: torch.Size([])\n",
      "preds: (tensor([[[ 0.0096, -1.4032,  1.0565,  ..., -0.2951, -0.7156, -0.4563],\n",
      "         [-0.1042,  0.0216,  0.9074,  ..., -1.5325,  0.0642, -1.1931],\n",
      "         [ 0.0074, -1.0180, -0.1519,  ..., -1.1090,  0.3688, -0.7764],\n",
      "         ...,\n",
      "         [ 0.1152, -0.1989,  0.3614,  ..., -0.8293,  0.0494, -0.7065],\n",
      "         [ 0.7021, -0.8486, -0.1324,  ..., -0.6438, -0.6686, -0.5303],\n",
      "         [-0.0576, -0.7737, -0.8084,  ..., -2.5327,  1.8250, -0.4494]]]), None, tensor(0.9931), None, None, None)\n"
     ]
    }
   ],
   "source": [
    "# data = aaa\n",
    "data = data_last\n",
    "\n",
    "x = data['batch_series']\n",
    "\n",
    "testx = torch.Tensor(x).to(device).float()\n",
    "\n",
    "print('testx shape:', testx.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = engine.model(testx, None)\n",
    "print('preds len:', preds[2].shape)\n",
    "print('preds:', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "733738b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9931])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if testx.shape[0] == 1:\n",
    "    pred_y =  torch.tensor([preds[2]])\n",
    "else:\n",
    "    pred_y = preds[2]\n",
    "\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51d3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712a0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d45c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34441, 7, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/export/home2/zongqi001/004_TimeKD/TimeKD/ETTm1/24/train_batch/batch.h5'\n",
    "\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    data = hf['stacked_embeddings'][:]\n",
    "    tensor = torch.from_numpy(data)\n",
    "\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7273842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([220, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/export/home2/zongqi001/004_TimeKD/TimeKD/amex_emb/train/0.h5'\n",
    "\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    data = hf['stacked_embeddings'][:]\n",
    "    tensor = torch.from_numpy(data)\n",
    "\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e00cdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 220, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_stack = [tensor.squeeze(0).detach(), tensor.squeeze(0).detach()]\n",
    "stacked_embeddings = torch.stack(embeddings_stack, dim=0)\n",
    "stacked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4839a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_stack = []\n",
    "embeddings = tensor\n",
    "embeddings_stack.append(tensor.squeeze(0).detach())\n",
    "embeddings_stack.append(tensor.squeeze(0).detach())\n",
    "\n",
    "stacked_embeddings = torch.stack(embeddings_stack, dim=0)\n",
    "stacked_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/home/zongqi/004_TimeKD/TimeKD/test_h5.h5'\n",
    "# with h5py.File(file_path, 'w') as hf:\n",
    "#     hf.create_dataset('embeddings', data=stacked_embeddings.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d51946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7, 768)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with h5py.File(file_path, 'r') as hf:\n",
    "#     data = hf['embeddings'][:]\n",
    "#     tensor = torch.from_numpy(data)\n",
    "\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f981b85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = stacked_embeddings\n",
    "\n",
    "temp_list = []\n",
    "temp_list.append(temp)\n",
    "temp_list.append(temp)\n",
    "\n",
    "stacked_temp = torch.cat(temp_list, dim=0)\n",
    "stacked_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131596c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69cbe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 7, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/home/zongqi/004_TimeKD/TimeKD/ETTm1/24/train_batch/batch.h5'\n",
    "\n",
    "with h5py.File(file_path, 'r') as hf:\n",
    "    data = hf['stacked_embeddings'][:]\n",
    "    tensor = torch.from_numpy(data)\n",
    "\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444bc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6eedd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_specs</th>\n",
       "      <th>is_predict</th>\n",
       "      <th>amex_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_specs  is_predict  amex_metric\n",
       "0          sd        True         0.06"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "log_df = pd.DataFrame()\n",
    "log_df['model_specs'] = ['sd'] \n",
    "log_df['is_predict'] = [True]\n",
    "log_df['amex_metric'] = [0.06]\n",
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ed8e234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"model_specs\":\"sd\",\"is_predict\":true,\"amex_metric\":0.06}]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_str = log_df.to_json(orient='records')\n",
    "json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8119f86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_specs</th>\n",
       "      <th>is_predict</th>\n",
       "      <th>amex_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_specs  is_predict  amex_metric\n",
       "0          sd        True         0.06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading back\n",
    "df_new = pd.read_json(json_str, orient='records')\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef947ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59a7527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44822e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>amex_metric</th>\n",
       "      <th>AUC</th>\n",
       "      <th>sampling</th>\n",
       "      <th>data_type</th>\n",
       "      <th>seed</th>\n",
       "      <th>test_duration</th>\n",
       "      <th>train_duration</th>\n",
       "      <th>log_time</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>es_patience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.723216</td>\n",
       "      <td>0.944534</td>\n",
       "      <td>10pct</td>\n",
       "      <td>original</td>\n",
       "      <td>420</td>\n",
       "      <td>30.428835</td>\n",
       "      <td>-12896.482947</td>\n",
       "      <td>2026-01-08 09:39:43</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.721458</td>\n",
       "      <td>0.945337</td>\n",
       "      <td>10pct</td>\n",
       "      <td>original</td>\n",
       "      <td>4200</td>\n",
       "      <td>25.758896</td>\n",
       "      <td>-13371.015694</td>\n",
       "      <td>2026-01-08 13:23:09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr  amex_metric       AUC sampling data_type  seed  test_duration  \\\n",
       "87  0.001     0.724133  0.945280    10pct  original   420      30.428835   \n",
       "88  0.001     0.721458  0.945337    10pct  original  4200      25.758896   \n",
       "\n",
       "    train_duration             log_time  batch_size  es_patience  \n",
       "87   -12896.482947  2026-01-08 09:39:43         4.0          5.0  \n",
       "88   -13371.015694  2026-01-08 13:23:09         4.0          5.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"experiment_log.csv\")\n",
    "df['batch_size'] = df['batch_size'].fillna(4)\n",
    "df['es_patience'] = df['es_patience'].fillna(5)\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd3ed41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>amex_metric</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th>sampling</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>es_patience</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">13month</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1pct</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.622110</td>\n",
       "      <td>0.890575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.660927</td>\n",
       "      <td>0.902529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.672143</td>\n",
       "      <td>0.913563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">10pct</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.744875</td>\n",
       "      <td>0.948273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.740360</td>\n",
       "      <td>0.947558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.722873</td>\n",
       "      <td>0.941117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1pct</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.754687</td>\n",
       "      <td>0.937823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.771580</td>\n",
       "      <td>0.941376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.773315</td>\n",
       "      <td>0.943713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">original</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.1pct</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.525237</td>\n",
       "      <td>0.887140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.641773</td>\n",
       "      <td>0.930451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.946046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">10pct</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>16.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.940601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.740925</td>\n",
       "      <td>0.947796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.747132</td>\n",
       "      <td>0.948982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.945360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.727159</td>\n",
       "      <td>0.945745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>16.0</th>\n",
       "      <th>3.0</th>\n",
       "      <td>0.692889</td>\n",
       "      <td>0.937602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1pct</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.686443</td>\n",
       "      <td>0.927326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00100</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.690086</td>\n",
       "      <td>0.930296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01000</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.688191</td>\n",
       "      <td>0.923726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   amex_metric       AUC\n",
       "data_type sampling lr      batch_size es_patience                       \n",
       "13month   0.1pct   0.00010 4.0        5.0             0.622110  0.890575\n",
       "                   0.00100 4.0        5.0             0.660927  0.902529\n",
       "                   0.01000 4.0        5.0             0.672143  0.913563\n",
       "          10pct    0.00010 4.0        5.0             0.744875  0.948273\n",
       "                   0.00100 4.0        5.0             0.740360  0.947558\n",
       "                   0.01000 4.0        5.0             0.722873  0.941117\n",
       "          1pct     0.00010 4.0        5.0             0.754687  0.937823\n",
       "                   0.00100 4.0        5.0             0.771580  0.941376\n",
       "                   0.01000 4.0        5.0             0.773315  0.943713\n",
       "original  0.1pct   0.00010 4.0        5.0             0.525237  0.887140\n",
       "                   0.00100 4.0        5.0             0.641773  0.930451\n",
       "                   0.01000 4.0        5.0             0.654517  0.946046\n",
       "          10pct    0.00001 16.0       3.0             0.713648  0.940601\n",
       "                   0.00010 4.0        5.0             0.740925  0.947796\n",
       "                           16.0       3.0             0.747132  0.948982\n",
       "                   0.00100 4.0        5.0             0.724668  0.945360\n",
       "                           16.0       3.0             0.727159  0.945745\n",
       "                   0.01000 16.0       3.0             0.692889  0.937602\n",
       "          1pct     0.00010 4.0        5.0             0.686443  0.927326\n",
       "                   0.00100 4.0        5.0             0.690086  0.930296\n",
       "                   0.01000 4.0        5.0             0.688191  0.923726"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['data_type', 'sampling','lr','batch_size','es_patience'])[['amex_metric','AUC']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbe682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378c237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 11:48:12\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "formatted_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(formatted_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ee4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c621878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.000055\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "t1 = datetime.now()\n",
    "t2 = datetime.now()\n",
    "t_diff = t2-t1\n",
    "print(t_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ef9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a3bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e187011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# df[['amex_metric', 'AUC']] = pd.DataFrame(df['score'].apply(ast.literal_eval).tolist(), index=df.index)\n",
    "# df = df.drop(columns=['score'])\n",
    "# df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ea312ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the new column order\n",
    "# cols = ['lr', 'amex_metric', 'AUC', 'sampling', 'data_type', 'seed', 'test_duration', 'train_duration']\n",
    "\n",
    "# # Apply the new order\n",
    "# df = df[cols]\n",
    "\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fadeb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['data_type', 'sampling','lr'])[['amex_metric','AUC']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a19c88d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[('train_duration' if c == 'test_duration' else 'test_duration' if c == 'train_duration' else c) for c in df.columns]]\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a60273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./experiment_log2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a5ab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "aaa = np.array([[1,2,3,4]])\n",
    "aaa[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175051fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e01321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-08 16:04:28.816466\n",
      "2026-01-08 16:04:28.816531\n",
      "0:00:00.000065\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "t1 = datetime.now()\n",
    "t2 = datetime.now()\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f2761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7003329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amex__TimeKD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
